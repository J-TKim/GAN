{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial_AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uggQo61Pg1JH"
      },
      "source": [
        "<table align=\"left\">\r\n",
        "  <td>\r\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/J-TKim/GAN/blob/master/Vanila_GAN.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\r\n",
        "  </td>\r\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEgSqtakq_U8"
      },
      "source": [
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import itertools\r\n",
        "\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWTFca6Xr9ih"
      },
      "source": [
        "os.makedirs('images', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAVLcsTbsFgg"
      },
      "source": [
        "# 주피터 노트북에서 실행시키기 위한 args class생성\r\n",
        "\r\n",
        "class args:\r\n",
        "    def __init__(self, n_epochs=200, batch_size=64, lr=0.0002, b1=0.5, b2=0.999, n_cpu=8, latent_dim=100, img_size=28, channels=1, sample_interval=400):\r\n",
        "        self.n_epochs = n_epochs\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.lr =lr\r\n",
        "        self.b1 = b1\r\n",
        "        self.b2 = b2\r\n",
        "        self.n_cpu = n_cpu\r\n",
        "        self.latent_dim = latent_dim\r\n",
        "        self.img_size = img_size\r\n",
        "        self.channels = channels\r\n",
        "        self.sample_interval = sample_interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFG2RsHcsGAI"
      },
      "source": [
        "args = args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J_8L8aHsHJY"
      },
      "source": [
        "img_shape = (args.channels, args.img_size, args.img_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qpPOgkQsIh5"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EfWNtuzsKUA"
      },
      "source": [
        "def reparameterization(mu, logvar):\r\n",
        "    std = torch.exp(logvar / 2)\r\n",
        "    sampled_z = Variable(Tensor(np.random.normal(0, 1, (mu.size(0), args.latent_dim))))\r\n",
        "    z = sampled_z * std + mu\r\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G9p2X5Ks9Ki"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Linear(512, 512),\r\n",
        "            nn.BatchNorm1d(512),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "        )\r\n",
        "\r\n",
        "        self.mu = nn.Linear(512, args.latent_dim)\r\n",
        "        self.logvar = nn.Linear(512, args.latent_dim)\r\n",
        "\r\n",
        "    def forward(self, img):\r\n",
        "        img_flat = img.view(img.shape[0], -1)\r\n",
        "        x = self.model(img_flat)\r\n",
        "        mu = self.mu(x)\r\n",
        "        logvar = self.logvar(x)\r\n",
        "        z = reparameterization(mu, logvar)\r\n",
        "        return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LICUOMtvgHI"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Linear(args.latent_dim, 512),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Linear(512, 512),\r\n",
        "            nn.BatchNorm1d(512),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Linear(512, int(np.prod(img_shape))),\r\n",
        "            nn.Tanh(),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, z):\r\n",
        "        img_flat = self.model(z)\r\n",
        "        img = img_flat.view(img_flat.shape[0], *img_shape)\r\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4_K4fWAv-yy"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Linear(args.latent_dim, 512),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Linear(512, 256),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Linear(256, 1),\r\n",
        "            nn.Sigmoid(),\r\n",
        "        )\r\n",
        "    \r\n",
        "    def forward(self, z):\r\n",
        "        validity = self.model(z)\r\n",
        "        return validity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0cVbGuEw23q"
      },
      "source": [
        "# Use binary cross-entropy loss\r\n",
        "adversarial_loss = torch.nn.BCELoss()\r\n",
        "pixelwise_loss = torch.nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnIIbW3OxClY"
      },
      "source": [
        "# Initialize generator and discriminator\r\n",
        "encoder = Encoder()\r\n",
        "decoder = Decoder()\r\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NojeOh7kxJUQ"
      },
      "source": [
        "encoder.to(device)\r\n",
        "decoder.to(device)\r\n",
        "discriminator.to(device)\r\n",
        "adversarial_loss.to(device)\r\n",
        "pixelwise_loss.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Rneaynxgdx"
      },
      "source": [
        "os.makedirs('./data/mnist', exist_ok=True)\r\n",
        "dataloader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST(\r\n",
        "        './data/mnist',\r\n",
        "        train=True,\r\n",
        "        download=True,\r\n",
        "        transform=transforms.Compose(\r\n",
        "            [transforms.Resize(args.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\r\n",
        "        ),\r\n",
        "    ),\r\n",
        "    batch_size=args.batch_size,\r\n",
        "    shuffle =True,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3_cL9bUyVeh"
      },
      "source": [
        "# Optimizers\r\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(encoder.parameters(), decoder.parameters()), lr=args.lr, betas=(args.b1, args.b2))\r\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.lr, betas=(args.b1, args.b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mavEHFXlyrfi"
      },
      "source": [
        "Tensor = torch.cuda.FloatTensor if device != torch.device('cpu') else torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEfoyZYIy2NJ"
      },
      "source": [
        "def sample_image(n_row, batches_done):\r\n",
        "    \"\"\"Saves a grid of generated digits\"\"\"\r\n",
        "    # Sample noise\r\n",
        "    z = Variable(Tensor(np.random.normal(0, 1, (n_row ** 2, args.latent_dim))))\r\n",
        "    gen_imgs = decoder(z)\r\n",
        "    save_image(gen_imgs.data, 'images/%d.png' % batches_done, nrow=n_row, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7OiwrKqy3HY"
      },
      "source": [
        "# Training\r\n",
        "\r\n",
        "for epoch in range(args.n_epochs):\r\n",
        "    for i, (imgs, _) in enumerate(dataloader):\r\n",
        "\r\n",
        "        # Adversarial ground thruths\r\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\r\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\r\n",
        "\r\n",
        "        # Conhfigure input\r\n",
        "        real_imgs = Variable(imgs.type(Tensor))\r\n",
        "\r\n",
        "        # Train Generator\r\n",
        "        optimizer_G.zero_grad()\r\n",
        "\r\n",
        "        encoded_imgs = encoder(real_imgs)\r\n",
        "        decoded_imgs = decoder(encoded_imgs)\r\n",
        "\r\n",
        "        # Loss measures generator's ability to fool the discriminator\r\n",
        "        g_loss = 0.001 * adversarial_loss(discriminator(encoded_imgs), valid) + 0.999 * pixelwise_loss(decoded_imgs, real_imgs)\r\n",
        "\r\n",
        "        g_loss.backward()\r\n",
        "        optimizer_G.step()\r\n",
        "\r\n",
        "        # Train Discriminator\r\n",
        "\r\n",
        "        optimizer_D.zero_grad()\r\n",
        "\r\n",
        "        # Sample noise as discriminator ground truth\r\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], args.latent_dim))))\r\n",
        "\r\n",
        "        # Measure discriminator's ability to classify real from generated samples\r\n",
        "        real_loss = adversarial_loss(discriminator(z), valid)\r\n",
        "        fake_loss = adversarial_loss(discriminator(encoded_imgs.detach()), fake)\r\n",
        "        d_loss = 0.5 * (real_loss + fake_loss)\r\n",
        "\r\n",
        "        d_loss.backward()\r\n",
        "        optimizer_D.step()\r\n",
        "\r\n",
        "        # print('[Epcoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]' % (epoch, args.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()))\r\n",
        "\r\n",
        "        batches_done = epoch * len(dataloader) + i\r\n",
        "        if batches_done % args.sample_interval == 0:\r\n",
        "            sample_image(n_row=10, batches_done=batches_done)\r\n",
        "\r\n",
        "    print('[Epcoch %d/%d] [D loss: %f] [G loss: %f]' % (epoch, args.n_epochs, d_loss.item(), g_loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFNi-7S0Z76X"
      },
      "source": [
        "import cv2\r\n",
        "from pathlib import Path\r\n",
        "def count_data(path, label):\r\n",
        "    path=Path(PATH + label)\r\n",
        "    #path=path.glob(\"*.jpg\")\r\n",
        "    images=[]\r\n",
        "    cnt = 0\r\n",
        "    for imagepath in path.glob('*.png'):\r\n",
        "        cnt += 1\r\n",
        "\r\n",
        "    return cnt    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRnjkUQwZ84L"
      },
      "source": [
        "PATH = '/content/images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfrlF2lAZ9wH"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "for idx in range(0, count_data(PATH, ''), 10):\r\n",
        "    name = str(idx * args.sample_interval) + '.png'\r\n",
        "    img = Image.open(PATH+name)\r\n",
        "    plt.imshow(img)\r\n",
        "    plt.title(name)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}