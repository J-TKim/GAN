{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1iFw3QdqU0i"
      },
      "source": [
        "<table align=\"left\">\r\n",
        "  <td>\r\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/J-TKim/GAN/blob/master/DCGAN.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\r\n",
        "  </td>\r\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waVlTv5vO7PV"
      },
      "source": [
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU0-BdWRO8c4"
      },
      "source": [
        "os.makedirs('images', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3lHzkHiPD53"
      },
      "source": [
        "# 주피터 노트북에서 실행시키기 위한 args class생성\r\n",
        "\r\n",
        "class args:\r\n",
        "    def __init__(self, n_epochs=200, batch_size=64, lr=0.0002, b1=0.5, b2=0.999, n_cpu=8, latent_dim=100, img_size=32, channels=1, sample_interval=400):\r\n",
        "        self.n_epochs = n_epochs\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.lr =lr\r\n",
        "        self.b1 = b1\r\n",
        "        self.b2 = b2\r\n",
        "        self.n_cpu = n_cpu\r\n",
        "        self.latent_dim = latent_dim\r\n",
        "        self.img_size = img_size\r\n",
        "        self.channels = channels\r\n",
        "        self.sample_interval = sample_interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYrIoSdGPpC2"
      },
      "source": [
        "args = args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kMwq5aGPqkf"
      },
      "source": [
        "img_shape = (args.channels, args.img_size, args.img_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0iziG-dP2Rf"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L922FKUzcFDU"
      },
      "source": [
        "def weights_init_normal(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find(\"Conv\") != -1:\r\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\r\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\r\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\r\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbX-v_jlQCHw"
      },
      "source": [
        "class Generator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "\r\n",
        "        self.init_size = args.img_size // 4\r\n",
        "        self.l1 = nn.Sequential(nn.Linear(args.latent_dim, 128 * self.init_size ** 2))\r\n",
        "\r\n",
        "        self.conv_blocks = nn.Sequential(\r\n",
        "            nn.BatchNorm2d(128),\r\n",
        "            nn.Upsample(scale_factor=2),\r\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\r\n",
        "            nn.BatchNorm2d(128, 0.8),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Upsample(scale_factor=2),\r\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\r\n",
        "            nn.BatchNorm2d(64, 0.8),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Conv2d(64, args.channels, 3, stride=1, padding=1),\r\n",
        "            nn.Tanh(),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, z):\r\n",
        "        out = self.l1(z)\r\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\r\n",
        "        img = self.conv_blocks(out)\r\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tAtCzRwQVEQ"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\r\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\r\n",
        "            if bn:\r\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\r\n",
        "            return block\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            *discriminator_block(args.channels, 16, bn=False),\r\n",
        "            *discriminator_block(16, 32),\r\n",
        "            *discriminator_block(32, 64),\r\n",
        "            *discriminator_block(64, 128),\r\n",
        "        )\r\n",
        "\r\n",
        "        # The height and width of downsampled image\r\n",
        "        ds_size = args.img_size // 2 ** 4\r\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\r\n",
        "\r\n",
        "    def forward(self, img):\r\n",
        "        out = self.model(img)\r\n",
        "        out = out.view(out.shape[0], -1)\r\n",
        "        validity = self.adv_layer(out)\r\n",
        "\r\n",
        "        return validity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFdNK-GRWSbf"
      },
      "source": [
        "# Loss function\r\n",
        "adversarial_loss = torch.nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYkwCyp_WlDf"
      },
      "source": [
        "# Initialize generator and discriminator\r\n",
        "generator = Generator()\r\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri6KQdUFWn4X"
      },
      "source": [
        "if device == torch.device(\"cuda:0\"):\r\n",
        "    generator.cuda()\r\n",
        "    discriminator.cuda()\r\n",
        "    adversarial_loss.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0gGK-Vpb_mo"
      },
      "source": [
        "# Initialize weights\r\n",
        "generator.apply(weights_init_normal)\r\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjh7U44XXEkf"
      },
      "source": [
        "# Configure data loader\r\n",
        "os.makedirs('./data/mnist', exist_ok=True)\r\n",
        "dataloader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST(\r\n",
        "        './data/mnist',\r\n",
        "        train=True,\r\n",
        "        download=True,\r\n",
        "        transform=transforms.Compose(\r\n",
        "            [transforms.Resize(args.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\r\n",
        "        ),\r\n",
        "    ),\r\n",
        "    batch_size=args.batch_size,\r\n",
        "    shuffle =True,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0rhjYQBYEah"
      },
      "source": [
        "# Optimizers\r\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=args.lr, betas=(args.b1, args.b2))\r\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.lr, betas=(args.b1, args.b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDcuXP8sYWjf"
      },
      "source": [
        "Tensor = torch.cuda.FloatTensor if device == torch.device(\"cuda:0\") else torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v70Pp9vpYcf_"
      },
      "source": [
        "# Training\r\n",
        "for epoch in range(args.n_epochs):\r\n",
        "    for i, (imgs, _) in enumerate(dataloader):\r\n",
        "\r\n",
        "        # Adversarial ground truths\r\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\r\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\r\n",
        "\r\n",
        "        # Configure input\r\n",
        "        real_imgs = Variable(imgs.type(Tensor))\r\n",
        "\r\n",
        "        # -----------------\r\n",
        "        #  Train Generator\r\n",
        "        # -----------------\r\n",
        "\r\n",
        "        optimizer_G.zero_grad()\r\n",
        "\r\n",
        "        # Sample noise as generator input\r\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], args.latent_dim))))\r\n",
        "\r\n",
        "        # Generate a batch of images\r\n",
        "        gen_imgs = generator(z)\r\n",
        "\r\n",
        "        # Loss measures generator's ability to fool the discriminator\r\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\r\n",
        "\r\n",
        "        g_loss.backward()\r\n",
        "        optimizer_G.step()\r\n",
        "\r\n",
        "        # Train Discriminator\r\n",
        "\r\n",
        "        optimizer_D.zero_grad()\r\n",
        "\r\n",
        "        # measures discriminator's ability to classify real from generated samples\r\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\r\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\r\n",
        "        d_loss = (real_loss + fake_loss) / 2\r\n",
        "\r\n",
        "        d_loss.backward()\r\n",
        "        optimizer_D.step()\r\n",
        "\r\n",
        "        batches_done = epoch * len(dataloader) + i\r\n",
        "        if batches_done % args.sample_interval == 0:\r\n",
        "            save_image(gen_imgs.data[:25], 'images/%d.png' % batches_done, nrow=5, normalize=True)\r\n",
        "    \r\n",
        "    print('[Epoch %d/%d] [D loss: %f] [G loss: %f]' % (epoch, args.n_epochs, d_loss.item(), g_loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67fM7N8SbxG_"
      },
      "source": [
        "import cv2\r\n",
        "from pathlib import Path\r\n",
        "def count_data(path, label):\r\n",
        "    path=Path(PATH + label)\r\n",
        "    #path=path.glob(\"*.jpg\")\r\n",
        "    images=[]\r\n",
        "    cnt = 0\r\n",
        "    for imagepath in path.glob('*.png'):\r\n",
        "        cnt += 1\r\n",
        "\r\n",
        "    return cnt    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkyUlc_ffGx"
      },
      "source": [
        "PATH = '/content/images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEBoEW_3fiKY"
      },
      "source": [
        "count_data(PATH, '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfVRLVPmflfY"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "for idx in range(0, count_data(PATH, ''), 10):\r\n",
        "    name = str(idx * args.sample_interval) + '.png'\r\n",
        "    img = Image.open(PATH+name)\r\n",
        "    plt.imshow(img)\r\n",
        "    plt.title(name)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}